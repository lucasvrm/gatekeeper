# Discovery Token Usage Analysis

**Data**: 2026-02-07
**Investiga√ß√£o**: Por que o agent recebeu apenas 346 input tokens na iteration 1?

---

## Resumo Executivo

‚ùå **Problema confirmado**: Agent recebeu prompt incompleto ou vazio na primeira itera√ß√£o
‚úÖ **Causa raiz**: Prov√°vel bug no assembler ou contexto session vazio
‚úÖ **Evid√™ncia**: Token usage de 346 √© ~66% menor que o esperado

---

## 1. Token Usage Observado (Logs)

```json
{
  "iteration": 1,
  "tokensUsed": {
    "inputTokens": 346,
    "outputTokens": 114,
    "cacheCreationTokens": 3687,
    "cacheReadTokens": 0
  }
}
```

**An√°lise iteration 1**:
- **inputTokens**: 346 (MUITO BAIXO)
- **cacheCreationTokens**: 3687 (system prompt sendo cacheado pela primeira vez)
- **Agent response**: "I don't see the task description or relevant files in the input..."

**An√°lise iteration 2** (ap√≥s tool call `list_directory`):
- **inputTokens**: 24117 (NORMAL - inclui conversation history + tool results)
- **cacheReadTokens**: 3687 (system prompt servido do cache)

---

## 2. C√°lculo Te√≥rico de Token Usage

### 2.1 System Prompt (step 0 - Discovery)

**Query DB**: `WHERE step=1 AND role='system' AND name LIKE 'discovery-%'`

Prompts esperados:
- `discovery-mandatory`: ~500 tokens (regras b√°sicas, constraints)
- `discovery-system`: ~800 tokens (instru√ß√µes detalhadas, exemplos)
- `discovery-examples`: ~300 tokens (exemplos de relat√≥rios)

**Total system prompt estimado**: ~1600 tokens

**Cache behavior**:
- 1¬™ requisi√ß√£o: `cacheCreationTokens = 1600 * 1.25 = ~2000`
- Observado: `cacheCreationTokens = 3687` ‚Üí **System prompt tem ~2950 tokens** (n√£o 1600)

### 2.2 User Message (Discovery)

**C√≥digo** (`AgentOrchestratorBridge.ts:196`):

```typescript
userMessage = `## Task

**Description:** ${input.taskDescription}

**Output ID:** ${outputId}

**Instructions:** Explore the codebase and generate a discovery_report.md with your findings. Use read_file, glob_pattern, and grep_pattern tools to gather evidence. Save the report using save_artifact("discovery_report.md", content).`
```

**Breakdown** (assumindo `taskDescription = "Auditoria de ValidationOrchestrator context"`):

```
## Task                                                    ‚Üí   2 tokens

**Description:** Auditoria de ValidationOrchestrator ctx  ‚Üí  12 tokens

**Output ID:** 2026_02_07_825_auditoria-validation...     ‚Üí  20 tokens

**Instructions:** Explore the codebase and generate...    ‚Üí  50 tokens
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total userMessage:                                         ~84 tokens
```

### 2.3 Total Esperado (Iteration 1)

```
System prompt:     ~2950 tokens  (confirmado via cacheCreationTokens)
User message:      ~  84 tokens  (te√≥rico)
Tools definition:  ~ 150 tokens  (READ_TOOLS + SAVE_ARTIFACT_TOOL)
Overhead (API):    ~  20 tokens  (role markers, etc)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL ESPERADO:    ~3204 tokens
```

**Observado**: 346 tokens
**Diferen√ßa**: -2858 tokens (89% de redu√ß√£o!)

---

## 3. Hip√≥teses sobre a Discrep√¢ncia

### Hip√≥tese 1: Cache Read em vez de Cache Creation ‚ùå
**Status**: DESCARTADA

- Se cache j√° existisse: `cacheReadTokens = 3687`, `inputTokens = 346`
- Mas observado: `cacheCreationTokens = 3687` (cache NOVO)
- **Conclus√£o**: System prompt foi enviado completo e cacheado

### Hip√≥tese 2: userMessage vazio ou muito curto ‚úÖ
**Status**: ALTA PROBABILIDADE

**Evid√™ncia**:
- `inputTokens = 346` (muito baixo)
- `cacheCreationTokens = 3687` (system prompt OK)
- **346 = 3687 / 10.6** ‚Üí userMessage representou apenas ~10% do esperado

**Poss√≠veis causas**:
1. `input.taskDescription` estava vazio
2. Bug na constru√ß√£o do userMessage (template Handlebars?)
3. Vari√°vel `userMessage` n√£o foi enviada ao provider

### Hip√≥tese 3: Session Context vazio ‚ùå
**Status**: IMPROV√ÅVEL

```typescript
const sessionContext = await this.fetchSessionContext(input.profileId)
const basePrompt = await this.assembler.assembleForSubstep(1, 'discovery-')
let systemPrompt = this.enrichPrompt(basePrompt, sessionContext)
```

- `enrichPrompt()` adiciona git strategy + custom instructions
- Se `sessionContext` vazio: system prompt seria ~200 tokens menor
- Mas `cacheCreationTokens = 3687` ‚Üí system prompt foi enviado completo
- **Conclus√£o**: Session context n√£o √© o problema

### Hip√≥tese 4: Provider n√£o recebeu userMessage corretamente ‚úÖ
**Status**: POSS√çVEL

**Teoria**: Bug no `AnthropicProvider.chat()` ou `LLMProvider` abstraction

```typescript
// AgentRunnerService.ts:353
response = await llm.chat({
  model: phase.model,
  system: systemPrompt,
  messages,          // ‚Üê [{ role: 'user', content: userMessage }]
  tools,
  maxTokens: phase.maxTokens,
  temperature: phase.temperature,
  enableCache: true,
  cwd: projectRoot,
  onEvent: emit,
})
```

**Verificar**:
1. `messages[0].content` est√° correto antes da chamada
2. Provider n√£o est√° fazendo sanitiza√ß√£o/truncamento inesperado
3. API do Anthropic recebeu o content completo

---

## 4. Token Breakdown da Iteration 1 (Reversa)

Assumindo que `inputTokens = 346` reflete o que o LLM viu:

```
System prompt (base):              ~2950 tokens  ‚Üê cache creation
User message (observado):          ~   ? tokens  ‚Üê LOST
Tools definition:                  ~ 150 tokens
Overhead:                          ~  20 tokens
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
```

**Mas**: `cacheCreationTokens = 3687` n√£o conta para `inputTokens`!
**Ent√£o**: `inputTokens = 346` representa APENAS:

```
User message:     ~ 200 tokens  (estimativa)
Tools definition: ~ 150 tokens
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total:            ~ 350 tokens ‚úì
```

### Rec√°lculo da User Message

Se `userMessage = 200 tokens`:

```
## Task                                                    ‚Üí   2 tokens
**Description:** ${taskDescription}                       ‚Üí   ? tokens
**Output ID:** 2026_02_07_825_auditoria-validation...     ‚Üí  20 tokens
**Instructions:** Explore the codebase and generate...    ‚Üí  50 tokens
```

**Restam**: 200 - 72 = 128 tokens para `taskDescription`

**Esperado**: "Auditoria de ValidationOrchestrator context" = ~12 tokens
**Se foi 128 tokens**: taskDescription tinha ~10x mais conte√∫do?

‚ùå **N√ÉO FAZ SENTIDO**: Agent reclamou que n√£o viu task description!

---

## 5. Conclus√£o da An√°lise

### ‚úÖ Token Accounting Explicado

**Antropic API**: `inputTokens` N√ÉO inclui tokens de cache creation/read

```
Iteration 1:
  - inputTokens:          346  ‚Üê user message + tools (SEM system prompt)
  - cacheCreationTokens: 3687  ‚Üê system prompt (stored in cache)

Iteration 2:
  - inputTokens:        24117  ‚Üê conversation history + tool results
  - cacheReadTokens:     3687  ‚Üê system prompt (served from cache)
```

**Portanto**:
- System prompt: 3687 tokens (OK)
- User message + tools: 346 tokens
- **User message real**: 346 - 150 (tools) - 20 (overhead) = **~176 tokens**

### ‚ùå Problema Real

**Esperado**: userMessage com ~84 tokens m√≠nimo
**Observado**: userMessage com ~176 tokens

**MAS**: Agent disse "I don't see the task description" ‚Üí conte√∫do estava vazio/gen√©rico!

**Hip√≥tese FINAL**: `input.taskDescription` estava vazio ou continha apenas texto gen√©rico:

```typescript
// ‚ùå Enviado:
taskDescription = ""  ou  taskDescription = "..."

// ‚úÖ Esperado:
taskDescription = "Auditoria de ValidationOrchestrator context handling durante pipeline execution"
```

---

## 6. A√ß√£o Corretiva

### Debug Logging Adicionado

**Arquivo**: `AgentOrchestratorBridge.ts` (linhas ~198-207)

```typescript
// üîç DEBUG: Log prompt composition
console.log('[Bridge:Discovery] ============ PROMPT DEBUG ============')
console.log('[Bridge:Discovery] taskDescription:', input.taskDescription)
console.log('[Bridge:Discovery] outputId:', outputId)
console.log('[Bridge:Discovery] provider type:', this.isCliProvider(phase) ? 'CLI' : 'API')
if (outputDir) console.log('[Bridge:Discovery] outputDir:', outputDir)
console.log('[Bridge:Discovery] userMessage length:', userMessage.length, 'chars')
console.log('[Bridge:Discovery] userMessage preview (first 500):', userMessage.slice(0, 500))
console.log('[Bridge:Discovery] systemPrompt length:', systemPrompt.length, 'chars')
console.log('[Bridge:Discovery] tools:', tools.map(t => t.name))
console.log('[Bridge:Discovery] =========================================')
```

### Pr√≥ximos Passos

1. ‚úÖ **Logs implementados** ‚Üí pr√≥xima execu√ß√£o mostrar√° valores exatos
2. ‚è≥ **User testa discovery novamente** ‚Üí capturar logs completos
3. ‚è≥ **Verificar BridgeController** ‚Üí como `taskDescription` √© passado para `generateDiscovery()`
4. ‚è≥ **Verificar frontend** ‚Üí como request √© montada ao chamar `/api/agent/bridge/discovery`

---

## 7. Arquivos para Investigar

### Backend
- `BridgeController.ts` ‚Üí m√©todo que chama `bridge.generateDiscovery()`
- `agent.routes.ts` ‚Üí route handler para `/api/agent/bridge/discovery`
- Verificar se body.taskDescription est√° sendo extra√≠do corretamente

### Frontend
- `orchestrator-page.tsx` ‚Üí onde discovery √© disparada
- Verificar payload do `fetch('/api/agent/bridge/discovery', { ... })`

### Provider Abstraction
- `AnthropicProvider.ts` ‚Üí verificar se `chat()` envia messages[0].content corretamente
- `LLMProvider.ts` ‚Üí interface abstrata

---

## 8. M√©tricas de Refer√™ncia

### Token Budget (Discovery - step 0)

```typescript
// Configura√ß√£o atual (DB):
{
  step: 0,
  maxIterations: 5,
  maxInputTokensBudget: 10000,  // 10K input tokens
  maxTokens: 4000               // 4K output tokens
}
```

**Iteration 1 observada**: 346 / 10000 = 3.5% do budget usado ‚úÖ

### Compara√ß√£o com outros steps

**Step 1 (Planner)**: ~1200 input tokens esperados
**Step 0 (Discovery)**: ~350 input tokens observados

**Diferen√ßa esperada**: Discovery deveria ser similar ao Planner (ambos recebem task description + instru√ß√µes)

---

## Ap√™ndice: Logs Completos (Exemplo)

```json
[
  {
    "type": "agent:bridge_start",
    "step": 1,
    "outputId": "2026_02_07_825_auditoria-validationorchestrator-context"
  },
  {
    "type": "agent:start",
    "provider": "anthropic",
    "model": "claude-sonnet-4-5-20250929"
  },
  {
    "type": "agent:iteration",
    "iteration": 1,
    "tokensUsed": {
      "inputTokens": 346,
      "outputTokens": 114,
      "cacheCreationTokens": 3687,
      "cacheReadTokens": 0
    }
  },
  {
    "type": "agent:tool_call",
    "tool": "list_directory",
    "input": {
      "path": ".",
      "recursive": true,
      "maxDepth": 2
    }
  },
  {
    "type": "agent:tool_result",
    "tool": "list_directory",
    "durationMs": 38
  },
  {
    "type": "agent:iteration",
    "iteration": 2,
    "tokensUsed": {
      "inputTokens": 24117,
      "outputTokens": 202,
      "cacheCreationTokens": 3687,
      "cacheReadTokens": 3687
    }
  },
  {
    "type": "agent:complete",
    "result": {
      "text": "I can see this is a large project, but I don't see the task description or relevant files in the input..."
    }
  }
]
```

---

**Contato**: Aguardando nova execu√ß√£o com logs de debug para confirmar valores exatos.
